# Desafio: Conversando por Voz com o ChatGPT via Whisper (OpenAI) e Python

Bem-vindo(a)! Este reposit√≥rio cont√©m a entrega do desafio de implementa√ß√£o de uma interface de voz utilizando o modelo **Whisper** da OpenAI para transcri√ß√£o de √°udio, integrado ao ambiente do Google Colab.

## üéØ Objetivo
O foco principal deste projeto √© a **transcri√ß√£o de √°udio em texto**, explorando a capacidade de processamento de linguagem natural do modelo Whisper. A implementa√ß√£o utiliza como base os conceitos e a estrutura de c√≥digo fornecida por **Venilton**, adaptando-os para capturar √°udio diretamente do navegador e process√°-lo via Python.

---

## üõ†Ô∏è Tecnologias e Bibliotecas Utilizadas

Para que a comunica√ß√£o entre o hardware (microfone) e o modelo de IA funcionasse perfeitamente no ambiente Cloud, foram implementadas as seguintes bibliotecas:

* **`whisper`**: O motor principal da OpenAI para o reconhecimento e transcri√ß√£o da fala.
* **`IPython.display (Javascript, Audio)`**: Utilizados para injetar scripts que permitem ao navegador gravar √°udio.
* **`google.colab.output`**: Essencial para a comunica√ß√£o entre o back-end do Python e o front-end do notebook.
* **`base64`**: Para decodificar os dados de √°udio capturados via JavaScript.
* **`IPython.core.interactiveshell`**: Para ajustes na execu√ß√£o das c√©lulas do ambiente.

### Trecho de Importa√ß√£o Base:
```python
from IPython.core.interactiveshell import InteractiveShell
from IPython.display import Javascript, Audio
from google.colab import output
from base64 import b64decode
import whisper
